# dvc.yaml
# 
# DVC pipeline configuration for data versioning and reproducible ML workflows
# Defines stages: data preparation, training, evaluation, and deployment
# Each stage tracks inputs, outputs, parameters, and metrics

stages:
  
  # ==============================================
  # STAGE 1: DATA PREPARATION
  # ==============================================
  prepare_data:
    cmd: python scripts/data_preparation.py
    deps:
      - data/raw/telco_churn_raw.csv
      - scripts/data_preparation.py
    outs:
      - data/processed/telco_churn.csv
      - data/processed/data_validation_report.html
    params:
      - data_prep.drop_columns
      - data_prep.missing_value_strategy
      - data_prep.validation_rules
    metrics:
      - reports/data_quality_metrics.json

  # ==============================================
  # STAGE 2: FEATURE ENGINEERING
  # ==============================================
  feature_engineering:
    cmd: python scripts/feature_engineering.py
    deps:
      - data/processed/telco_churn.csv
      - scripts/feature_engineering.py
    outs:
      - data/features/training_features.csv
      - data/features/feature_metadata.json
    params:
      - feature_eng.create_interaction_features
      - feature_eng.polynomial_features
      - feature_eng.feature_selection_threshold

  # ==============================================
  # STAGE 3: MODEL TRAINING
  # ==============================================
  train_model:
    cmd: python train_with_mlflow.py
    deps:
      - data/features/training_features.csv
      - train_with_mlflow.py
    outs:
      - model/best_churn_model.joblib
      - model/model_metadata.json
      - model/evaluation_metrics.png
    params:
      - training.models_to_try
      - training.cv_folds
      - training.test_size
      - training.random_seed
    metrics:
      - reports/training_metrics.json

  # ==============================================
  # STAGE 4: MODEL EVALUATION
  # ==============================================
  evaluate_model:
    cmd: python scripts/model_evaluation.py
    deps:
      - model/best_churn_model.joblib
      - data/features/training_features.csv
      - scripts/model_evaluation.py
    outs:
      - reports/model_evaluation_report.html
      - reports/feature_importance.png
      - reports/shap_explanations.png
    metrics:
      - reports/evaluation_metrics.json

  # ==============================================
  # STAGE 5: DATA DRIFT MONITORING
  # ==============================================
  monitor_drift:
    cmd: python scripts/drift_monitoring.py
    deps:
      - data/features/training_features.csv
      - data/monitoring/current_data.csv
      - scripts/drift_monitoring.py
    outs:
      - reports/drift_report.html
      - reports/drift_metrics.json
    metrics:
      - reports/drift_scores.json

---

# .dvcignore
# 
# Files and directories to ignore in DVC tracking
# Similar to .gitignore but for DVC operations

# Temporary files
*.tmp
*.temp
.DS_Store
Thumbs.db

# Python cache
__pycache__/
*.pyc
*.pyo
*.pyd
.Python
env/
venv/
.venv/

# IDE files
.vscode/
.idea/
*.swp
*.swo

# Logs
*.log
logs/

# Model artifacts that shouldn't be versioned
model/temp_*
model/*.pkl.tmp

# Large intermediate files
data/temp/
data/cache/

# OS generated files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

---

# params.yaml
#
# DVC parameters file for reproducible experiments
# Centralizes all hyperparameters and configuration settings

# ==============================================
# DATA PREPARATION PARAMETERS
# ==============================================
data_prep:
  drop_columns:
    - Customer ID
    - Lat Long
    - Latitude
    - Longitude
    - Zip Code
    - City
    - State
    - Country
    - Quarter
    - Churn Reason
    - Churn Score
    - Churn Category
    - Category
    - Customer Status
    - Dependents
    - Device Protection Plan
    - Gender
    - Under 30
    - Married
    - Number of Dependents
    - Number of Referrals
    - Payment Method
    - Offer
    - Online Backup
    - Online Security
    - Paperless Billing
    - Partner
    - Premium Tech Support
    - Referred a Friend
    - Senior Citizen
    - Total Refunds
  
  missing_value_strategy:
    numeric: median
    categorical: most_frequent
  
  validation_rules:
    min_samples: 1000
    max_missing_percentage: 0.3
    required_columns:
      - Monthly Charges
      - Total Charges
      - Tenure Months
      - Churn

# ==============================================
# FEATURE ENGINEERING PARAMETERS
# ==============================================
feature_eng:
  create_interaction_features: false
  polynomial_features: false
  feature_selection_threshold: 0.01
  
  feature_scaling:
    method: standard
    robust_scaling: false
  
  categorical_encoding:
    method: onehot
    handle_unknown: ignore
    drop_first: false

# ==============================================
# MODEL TRAINING PARAMETERS
# ==============================================
training:
  models_to_try:
    - logistic_regression
    - random_forest
    - gradient_boosting
    - xgboost  # Optional if available
  
  cv_folds: 5
  test_size: 0.2
  random_seed: 42
  
  class_balance_strategy: balanced
  scoring_metric: roc_auc
  
  hyperparameter_tuning:
    method: grid_search
    n_jobs: -1
    verbose: 1

# ==============================================
# MODEL EVALUATION PARAMETERS
# ==============================================
evaluation:
  metrics_to_calculate:
    - accuracy
    - precision
    - recall
    - f1
    - roc_auc
    - average_precision
  
  plot_types:
    - confusion_matrix
    - roc_curve
    - precision_recall_curve
    - feature_importance
    - shap_summary
  
  explanation_samples: 100
  shap_max_display: 20

# ==============================================
# MONITORING PARAMETERS
# ==============================================
monitoring:
  drift_detection:
    reference_window_days: 30
    current_window_days: 7
    drift_threshold: 0.1
    
  performance_monitoring:
    alert_thresholds:
      accuracy_drop: 0.05
      drift_score: 0.1
      prediction_volume_change: 0.5
    
  data_quality:
    missing_value_threshold: 0.1
    outlier_detection_method: iqr
    outlier_threshold: 3.0

# ==============================================
# DEPLOYMENT PARAMETERS
# ==============================================
deployment:
  model_serving:
    batch_size: 32
    timeout_seconds: 30
    max_concurrent_requests: 100
  
  api_configuration:
    rate_limiting:
      requests_per_minute: 1000
      burst_limit: 50
    
  monitoring_intervals:
    health_check_seconds: 30
    metrics_collection_minutes: 5
    drift_analysis_hours: 24